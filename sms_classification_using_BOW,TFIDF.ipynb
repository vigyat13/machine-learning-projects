{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.read_csv(\"/content/spam.csv\", encoding='latin-1')\n",
        "\n",
        "df.head()\n",
        "\n",
        "df.shape\n",
        "\n",
        "df.isnull().sum()\n",
        "\n",
        "df=df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'])\n",
        "\n",
        "df=df.rename(columns={\"v2\":\"message\",\"v1\":\"labels\"})\n",
        "\n",
        "df.head()\n",
        "\n",
        "df.duplicated()\n",
        "\n",
        "df.info()\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "ps=WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "\n",
        "corpus=[]\n",
        "for i in range (0,len(df['message'])):\n",
        "  review=re.sub('[^a-z A-Z]','',df[\"message\"][i])\n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "  review=[ps.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
        "  review=' '.join(review)\n",
        "  corpus.append(review)\n",
        "\n",
        "y=pd.get_dummies(df['labels'])\n",
        "y=y.iloc[:,1].values\n",
        "#train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(corpus, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "#use Bow method\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(max_features=2500,binary=True)\n",
        "X_train=cv.fit_transform(X_train).toarray()\n",
        "X_test=cv.transform(X_test).toarray()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # Import metrics\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Support Vector Machine\": SVC(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "\n",
        "}\n",
        "\n",
        "# Modify the evaluate_models function to handle the single-column target variable\n",
        "def evaluate_models(X_train, X_test, y_train, y_test, models: dict):\n",
        "    \"\"\"\n",
        "    Trains and evaluates multiple models.\n",
        "\n",
        "    Parameters:\n",
        "        X_train, X_test: your data splits\n",
        "        y_train, y_test: your single-column numeric target variable splits (e.g., 0/1)\n",
        "        models (dict): A dictionary of models e.g., {'Logistic Regression': LogisticRegression()}\n",
        "\n",
        "    Returns:\n",
        "        results_df: A DataFrame showing the scores of each model\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # y_train and y_test are already single-column Series after the change above\n",
        "    # No need to select 'spam' column here anymore\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Train the model using the single-column numeric labels\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Accuracy': accuracy_score(y_test, y_pred),\n",
        "            # Use pos_label=1 since 'spam' is encoded as 1\n",
        "            # Specify the labels that can appear in y_true and y_pred\n",
        "            'Precision': precision_score(y_test, y_pred, average='binary', pos_label=1, zero_division=0, labels=[0, 1]),\n",
        "            'Recall': recall_score(y_test, y_pred, average='binary', pos_label=1, zero_division=0, labels=[0, 1]),\n",
        "            'F1 Score': f1_score(y_test, y_pred, average='binary', pos_label=1, zero_division=0, labels=[0, 1])\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False)\n",
        "    return results_df\n",
        "\n",
        "results_df = evaluate_models(X_train, X_test, y_train, y_test, models)\n",
        "print(results_df)\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgF8FcGyj2Ua",
        "outputId": "7a1e9eb1-246a-4e30-d6ac-8be11eb9b3d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   labels   5572 non-null   object\n",
            " 1   message  5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Model  Accuracy  Precision    Recall  F1 Score\n",
            "1     Logistic Regression  0.979372   1.000000  0.845638  0.916364\n",
            "2  Support Vector Machine  0.976682   1.000000  0.825503  0.904412\n",
            "3           Random Forest  0.974888   0.984000  0.825503  0.897810\n",
            "0             Naive Bayes  0.973094   0.916084  0.879195  0.897260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using tfidf\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(corpus, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "LRWtyeA9p09u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf=TfidfVectorizer(max_features=2500,ngram_range=(1,3))\n",
        "X_train=tfidf.fit_transform(X_train).toarray()\n",
        "X_test=tfidf.transform(X_test).toarray()"
      ],
      "metadata": {
        "id": "bZOz3yZ3p_v1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # Import metrics\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Support Vector Machine\": SVC(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "xm7sDvPzqESh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_models(X_train, X_test, y_train, y_test, models: dict):\n",
        "    \"\"\"\n",
        "    Trains and evaluates multiple models.\n",
        "\n",
        "    Parameters:\n",
        "        X_train, X_test: your data splits\n",
        "        y_train, y_test: your single-column numeric target variable splits (e.g., 0/1)\n",
        "        models (dict): A dictionary of models e.g., {'Logistic Regression': LogisticRegression()}\n",
        "\n",
        "    Returns:\n",
        "        results_df: A DataFrame showing the scores of each model\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # y_train and y_test are already single-column Series after the change above\n",
        "    # No need to select 'spam' column here anymore\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Train the model using the single-column numeric labels\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Accuracy': accuracy_score(y_test, y_pred),\n",
        "            # Use pos_label=1 since 'spam' is encoded as 1\n",
        "            # Specify the labels that can appear in y_true and y_pred\n",
        "            'Precision': precision_score(y_test, y_pred, average='binary', pos_label=1, zero_division=0, labels=[0, 1]),\n",
        "            'Recall': recall_score(y_test, y_pred, average='binary', pos_label=1, zero_division=0, labels=[0, 1]),\n",
        "            'F1 Score': f1_score(y_test, y_pred, average='binary', pos_label=1, zero_division=0, labels=[0, 1])\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False)\n",
        "    return results_df\n",
        "\n",
        "results_df = evaluate_models(X_train, X_test, y_train, y_test, models)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyTw9nz5qOZb",
        "outputId": "0e8be0ed-0652-4800-8d37-8db5b652f22d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Model  Accuracy  Precision    Recall  F1 Score\n",
            "2  Support Vector Machine  0.982063   1.000000  0.865772  0.928058\n",
            "3           Random Forest  0.976682   0.984252  0.838926  0.905797\n",
            "0             Naive Bayes  0.972197   0.991667  0.798658  0.884758\n",
            "1     Logistic Regression  0.970404   0.983333  0.791946  0.877323\n"
          ]
        }
      ]
    }
  ]
}